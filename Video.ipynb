{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzzxNhIGuWk9"
      },
      "source": [
        "# Read a video file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from opencv-python) (2.2.5)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.13 -m pip install --upgrade pip\u001b[0m\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.13 -m pip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (3.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (2.2.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/kafiling/Library/Python/3.13/lib/python/site-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/kafiling/Library/Python/3.13/lib/python/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (3.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (2.2.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/kafiling/Library/Python/3.13/lib/python/site-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/kafiling/Library/Python/3.13/lib/python/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /Users/kafiling/Library/Python/3.13/lib/python/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.13 -m pip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: six>=1.5 in /Users/kafiling/Library/Python/3.13/lib/python/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.13 -m pip install --upgrade pip\u001b[0m\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement cv2 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.13 -m pip install --upgrade pip\u001b[0m\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement cv2 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.13 -m pip install --upgrade pip\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for cv2\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for cv2\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip3 install opencv-python\n",
        "!pip3 install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "LO9bcCMjtAqO",
        "outputId": "62678517-92c4-4857-94fd-91e118566419"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "# Path to the video file\n",
        "video_path = 'vtest.avi'\n",
        "\n",
        "# Open the video file\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Check if the video file opened successfully\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Unable to open video file.\")\n",
        "    exit()\n",
        "\n",
        "while True:\n",
        "    # Read frames from the video\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Break the loop if no frame is returned (end of video)\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Display the frame\n",
        "    cv2.imshow('Video Frame', frame)\n",
        "\n",
        "    # Break the loop on 'q' key press\n",
        "    if cv2.waitKey(33) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the video capture object and close windows\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbatLVcUuc-x"
      },
      "source": [
        "# Read a webcam stream in local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "macYSG-NuaOQ"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "# Open the webcam (usually device 0 for the default camera)\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "# Set video properties (optional)\n",
        "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
        "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
        "\n",
        "# Check if the webcam opened successfully\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Unable to access the webcam.\")\n",
        "    exit()\n",
        "\n",
        "while True:\n",
        "    # Read frames from the webcam\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Check if frame is successfully captured\n",
        "    if not ret:\n",
        "        print(\"Error: Unable to capture frame from webcam.\")\n",
        "        break\n",
        "\n",
        "    # Display the frame\n",
        "    cv2.imshow('Webcam Frame', frame)\n",
        "\n",
        "    # Break the loop on 'q' key press\n",
        "    if cv2.waitKey(33) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the webcam and close windows\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_716arf-DZs"
      },
      "source": [
        "# Frame differencing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "folvpztk-Mrr"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     41\u001b[39m     prev_gray = gray\n\u001b[32m     43\u001b[39m     \u001b[38;5;66;03m# Break the loop on 'q' key press\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m33\u001b[39;49m\u001b[43m)\u001b[49m & \u001b[32m0xFF\u001b[39m == \u001b[38;5;28mord\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mq\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     45\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Release the video capture object\u001b[39;00m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "\n",
        "# Path to the video file\n",
        "video_path = 'vtest.avi'\n",
        "\n",
        "# Open the video file\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Check if the video file opened successfully\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Unable to open video file.\")\n",
        "    exit()\n",
        "\n",
        "# Read the first frame\n",
        "ret, prev_frame = cap.read()\n",
        "\n",
        "# Convert the first frame to grayscale\n",
        "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "while True:\n",
        "    # Read the next frame\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Break the loop if no frame is returned (end of video)\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Convert the current frame to grayscale\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Compute the absolute difference between the current frame and the previous frame\n",
        "    frame_diff = cv2.absdiff(prev_gray, gray)\n",
        "\n",
        "    # Threshold the difference to highlight the changes\n",
        "    _, thresh_diff = cv2.threshold(frame_diff, 25, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Display the frame\n",
        "    cv2.imshow('Frame Differencing', thresh_diff)\n",
        "\n",
        "    # Set previous frame a current frame\n",
        "    prev_gray = gray\n",
        "\n",
        "    # Break the loop on 'q' key press\n",
        "    if cv2.waitKey(33) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the video capture object\n",
        "cap.release()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2mNFp9vwWOu"
      },
      "source": [
        "# Background subtraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0XcbUsxawVxH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Matplotlib is building the font cache; this may take a moment.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FFeQ_k70wau9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "OpenCV: Couldn't read video stream from file \"assets/vtest.avi\"\n"
          ]
        }
      ],
      "source": [
        "capture = cv2.VideoCapture('assets/vtest.avi')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxcJbz2r-j3U"
      },
      "source": [
        "A cv2.BackgroundSubtractor object will be used to generate the foreground mask.\n",
        "\n",
        "We use MOG background subtractor for this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RdCquy23wc0E"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'cv2' has no attribute 'bgsegm'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m backSub = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbgsegm\u001b[49m.createBackgroundSubtractorMOG()\n",
            "\u001b[31mAttributeError\u001b[39m: module 'cv2' has no attribute 'bgsegm'"
          ]
        }
      ],
      "source": [
        "backSub = cv2.bgsegm.createBackgroundSubtractorMOG()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NK8MqKj-vl_"
      },
      "source": [
        "Every frame is used both for calculating the foreground mask and for updating the background."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tBxgFRrXwfNC"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'backSub' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m ret, frame = capture.read()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m fgMask = \u001b[43mbackSub\u001b[49m.apply(frame)\n\u001b[32m      3\u001b[39m plt.imshow(fgMask)\n\u001b[32m      4\u001b[39m plt.show()\n",
            "\u001b[31mNameError\u001b[39m: name 'backSub' is not defined"
          ]
        }
      ],
      "source": [
        "ret, frame = capture.read()\n",
        "fgMask = backSub.apply(frame)\n",
        "plt.imshow(fgMask)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDAOGQNz-1Mr"
      },
      "source": [
        "Show the result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L14nx7xmwg02"
      },
      "outputs": [],
      "source": [
        "capture = cv2.VideoCapture('vtest.avi')\n",
        "backSub = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
        "while True:\n",
        "    ret, frame = capture.read()\n",
        "    if frame is None:\n",
        "        break\n",
        "\n",
        "    fgMask = backSub.apply(frame)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    cv2.rectangle(frame, (10, 2), (100,20), (255,255,255), -1)\n",
        "    cv2.putText(frame, str(capture.get(cv2.CAP_PROP_POS_FRAMES)), (15, 15),\n",
        "               cv2.FONT_HERSHEY_SIMPLEX, 0.5 , (0,0,0))\n",
        "\n",
        "\n",
        "    cv2.imshow('Frame', frame)\n",
        "    cv2.imshow('Mask', fgMask)\n",
        "\n",
        "    keyboard = cv2.waitKey(33)\n",
        "    if keyboard == 'q' or keyboard == 27:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_R5S95mwnUw"
      },
      "source": [
        "#Optical Flow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-50ujY2_3AK"
      },
      "source": [
        "Lucas-Kanade method computes optical flow for a sparse feature set (in our example, corners detected using Shi-Tomasi algorithm). OpenCV provides another algorithm to find the dense optical flow. It computes the optical flow for all the points in the frame. It is based on Gunnar Farneback's algorithm which is explained in \"Two-Frame Motion Estimation Based on Polynomial Expansion\" by Gunnar Farneback in 2003.\n",
        "\n",
        "Below sample shows how to find the dense optical flow using above algorithm. We get a 2-channel array with optical flow vectors, (u,v). We find their magnitude and direction. We color code the result for better visualization. Direction corresponds to Hue value of the image. Magnitude corresponds to Value plane."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMmIiSAZwv68"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TMtBtNywp9i"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture(\"vtest.avi\")\n",
        "ret, frame1 = cap.read()\n",
        "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
        "hsv = np.zeros_like(frame1)\n",
        "hsv[..., 1] = 255\n",
        "while(1):\n",
        "    ret, frame2 = cap.read()\n",
        "    if not ret:\n",
        "        print('No frames grabbed!')\n",
        "        break\n",
        "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
        "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
        "    hsv[..., 0] = ang*180/np.pi/2\n",
        "    hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
        "    bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "    cv2.imshow('Frame', frame2)\n",
        "    cv2.imshow('frame2', bgr)\n",
        "    k = cv2.waitKey(33) & 0xff\n",
        "    if k == 27:\n",
        "        break\n",
        "\n",
        "    prvs = next\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
